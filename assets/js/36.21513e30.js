(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{333:function(t,s,a){"use strict";a.r(s);var e=a(4),i=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"pytorch深度学习入门"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pytorch深度学习入门"}},[t._v("#")]),t._v(" "),s("strong",[t._v("Pytorch深度学习入门")])]),t._v(" "),s("blockquote",[s("p",[t._v("本文作者："),s("a",{attrs:{href:"https://wanghaohong1.github.io",target:"_blank",rel:"noopener noreferrer"}},[t._v("程序员whh"),s("OutboundLink")],1)]),t._v(" "),s("p",[t._v("本站地址："),s("a",{attrs:{href:"https://wanghaohong1.github.io",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://wanghaohong1.github.io"),s("OutboundLink")],1)])]),t._v(" "),s("p",[t._v("分享深度学习框架pytorch的基本知识和在cv和nlp方面的应用\n")]),t._v(" "),s("h2",{attrs:{id:"章节9-预训练模型-迁移学习"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节9-预训练模型-迁移学习"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节9 预训练模型（迁移学习）")])]),t._v(" "),s("img",{staticStyle:{zoom:"25%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240715171217973.png",alt:"image-20240715171217973"}}),t._v(" "),s("h3",{attrs:{id:"微调与迁移学习"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#微调与迁移学习"}},[t._v("#")]),t._v(" 微调与迁移学习")]),t._v(" "),s("blockquote",[s("p",[t._v("微调")])]),t._v(" "),s("p",[t._v("​\t只有分类器已经训练好了，才能微调卷积基的卷积层")]),t._v(" "),s("p",[t._v("​\t如果没有这样的话，刚开始的训练误差很大，微调之前这些卷积层学到的表示会被破坏掉")]),t._v(" "),s("ol",[s("li",[t._v("在预训练卷积基上添加自定义层")]),t._v(" "),s("li",[t._v("冻结卷积基所有层")]),t._v(" "),s("li",[t._v("训练添加的分类层")]),t._v(" "),s("li",[t._v("解冻卷积基的一部分层（一般解冻靠近输出的卷积基）")]),t._v(" "),s("li",[t._v("联合训练解冻的卷积层和添加的自定义层")])]),t._v(" "),s("h2",{attrs:{id:"章节11-现代网络架构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节11-现代网络架构"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节11 现代网络架构")])]),t._v(" "),s("h3",{attrs:{id:"resnet"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resnet"}},[t._v("#")]),t._v(" ResNet")]),t._v(" "),s("p",[t._v("是一种残差网络，可以把它理解为一个模块，这个模块经过堆叠可以构成一个很深的网络")]),t._v(" "),s("p",[t._v("ResNet通过增加残差连接（shortcut connection），显式地让网络中的层拟合残差映射")]),t._v(" "),s("img",{staticStyle:{zoom:"33%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240715213240096.png",alt:"image-20240715213240096"}}),t._v(" "),s("p",[t._v("ResNet不再尝试学习x到H(x)​的潜在映射，而是学习两者之间的不同，或说残差")]),t._v(" "),s("p",[t._v("然后，为了计算H(x)，可将残差加到输入上。假设残差是F(x)=H(x)-x，我们尝试学习F(x)+x而不是直接学习H(x)")]),t._v(" "),s("p",[t._v("实验表明"),s("strong",[t._v("学习残差")]),t._v("比直接学习输入、输出间映射要容易收敛，可达到更高的分类精度，ResNet在上百层都有很好的表现")]),t._v(" "),s("p",[t._v("ResNet中，所有的Residual Block都没有pooling层，降采样是通过conv的stride实现的")]),t._v(" "),s("p",[t._v("通过Average Pooling得到最终的特征，而不是通过全连接层；每个卷积层之后都紧接着BatchNorm层")]),t._v(" "),s("h3",{attrs:{id:"densenet"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#densenet"}},[t._v("#")]),t._v(" Densenet")]),t._v(" "),s("p",[t._v("ResNet使用了残差连接来搭建更深的网络。DenseNet更进一步，它引入了每层与所有后续层的连接，即每一层都接收所有前置层的特征平面作为输入")]),t._v(" "),s("p",[s("span",{staticClass:"katex-display"},[s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("msub",[s("mi",[t._v("X")]),s("mi",[t._v("l")])],1),s("mo",[t._v("=")]),s("msub",[s("mi",[t._v("H")]),s("mi",[t._v("l")])],1),s("mo",[t._v("(")]),s("msub",[s("mi",[t._v("x")]),s("mn",[t._v("0")])],1),s("mo",{attrs:{separator:"true"}},[t._v(",")]),s("msub",[s("mi",[t._v("x")]),s("mn",[t._v("1")])],1),s("mo",{attrs:{separator:"true"}},[t._v(",")]),s("msub",[s("mi",[t._v("x")]),s("mn",[t._v("2")])],1),s("mo",{attrs:{separator:"true"}},[t._v(",")]),s("mi",{attrs:{mathvariant:"normal"}},[t._v(".")]),s("mi",{attrs:{mathvariant:"normal"}},[t._v(".")]),s("mi",{attrs:{mathvariant:"normal"}},[t._v(".")]),s("mo",{attrs:{separator:"true"}},[t._v(",")]),s("msub",[s("mi",[t._v("x")]),s("mrow",[s("mi",[t._v("l")]),s("mo",[t._v("−")]),s("mn",[t._v("1")])],1)],1),s("mo",[t._v(")")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("X_l=H_l(x_0, x_1, x_2,...,x_{l-1})\n")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),s("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),s("span",{staticClass:"base displaystyle textstyle uncramped"},[s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.07847em"}},[t._v("X")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.07847em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.08125em"}},[t._v("H")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.08125em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit"},[t._v("x")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord mathrm"},[t._v("0")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mpunct"},[t._v(",")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit"},[t._v("x")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord mathrm"},[t._v("1")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mpunct"},[t._v(",")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit"},[t._v("x")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord mathrm"},[t._v("2")])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mpunct"},[t._v(",")]),s("span",{staticClass:"mord mathrm"},[t._v(".")]),s("span",{staticClass:"mord mathrm"},[t._v(".")]),s("span",{staticClass:"mord mathrm"},[t._v(".")]),s("span",{staticClass:"mpunct"},[t._v(",")]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathit"},[t._v("x")]),s("span",{staticClass:"vlist"},[s("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),s("span",{staticClass:"reset-textstyle scriptstyle cramped"},[s("span",{staticClass:"mord scriptstyle cramped"},[s("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mord mathrm"},[t._v("1")])])])]),s("span",{staticClass:"baseline-fix"},[s("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[s("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),s("span",{staticClass:"mclose"},[t._v(")")])])])])])]),t._v(" "),s("p",[t._v("对比于ResNet的Residual Block，创新性地提出Dense Block，在每一个Dense Block中，任何两层之间都有直接的连接，也就是说，网络每一层的输入都是前面所有层输出的并集")]),t._v(" "),s("p",[t._v("该层所学习的特征图也会被直接传给其后面所有层作为输入，通过密集连接，缓解梯度消失问题，加强特征传播，鼓励特征复用，极大减少了参数量")]),t._v(" "),s("p",[t._v("DenseNet的密集连接方式需要特征图大小保持一致。为了解决这个问题，DenseNet网络中使用DenseBlock + Transition的结构")]),t._v(" "),s("p",[t._v("其中DenseBlock是包含很多层的模块，每个层的特征图大小相同，层与层之间采用密集连接方式，而Transition模块是来连接两个相邻的DenseBlock ，并且通过Pooling使特征图大小降低。")]),t._v(" "),s("img",{staticStyle:{zoom:"40%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240716162214269.png",alt:"image-20240716162214269"}}),t._v(" "),s("h3",{attrs:{id:"inception"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#inception"}},[t._v("#")]),t._v(" Inception")]),t._v(" "),s("p",[t._v("在我们看到的大多数计算机视觉模型使用的深度学习算法中，要么用了滤波器尺寸为1*1、3*3、5*5、7*7的卷积层，要么用了平面池化层。Inception模块把不同滤波器尺寸的卷积组合在一起，并联合了所有的输出")]),t._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240717150019313.png",alt:"image-20240717150019313"}}),t._v(" "),s("p",[t._v("此结构主要有以下改进：")]),t._v(" "),s("ol",[s("li",[t._v("一层block就包含1*1卷积，3*3卷积，5*5卷积，3*3池化。网络中每一层都能学习到“稀疏”（3*3、5*5）或不稀疏（1*1）的特征，既增加了网络的宽度，也增加了网络对尺度的适应性")]),t._v(" "),s("li",[t._v("通过concat在每个block后合成特征，获得非线性属性")])]),t._v(" "),s("p",[t._v("为了降低算力，作者在3*3和5*5卷积层之前添加额外的1*1卷积层，来限制输入信道的数量")]),t._v(" "),s("p",[t._v("尽管添加额外的卷积操作似乎是反直觉的，但是1*1卷积比5*5卷积要廉价很多，而且输入信道数量减少也有利于降低算力成本")]),t._v(" "),s("p",[t._v("不过一定要注意，1*1卷积（能够缩减channel）是在最大池化层之后，而不是之前")]),t._v(" "),s("blockquote",[s("p",[t._v("结构特点")])]),t._v(" "),s("p",[t._v("在inception中，大量采用了1*1的矩阵，主要是两点作用：")]),t._v(" "),s("ol",[s("li",[t._v("对数据进行降维")]),t._v(" "),s("li",[t._v("引入更多的非线性，提高泛化能力，因为卷积后要经过ReLu激活函数")])]),t._v(" "),s("p",[t._v("1*1结构的卷积可大大减小参数数量")]),t._v(" "),s("h2",{attrs:{id:"章节12-简单图像定位"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节12-简单图像定位"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节12 简单图像定位")])]),t._v(" "),s("h3",{attrs:{id:"常见图像处理的任务"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常见图像处理的任务"}},[t._v("#")]),t._v(" 常见图像处理的任务")]),t._v(" "),s("p",[t._v("1）分类")]),t._v(" "),s("p",[t._v("给定一副图像，我们用计算机模型预测图片中有什么对像")]),t._v(" "),s("p",[t._v("2）分类+定位")]),t._v(" "),s("p",[t._v("不仅需要我们知道图片中的对像是什么，还要在对像的附近画一个近框，确定该对像所处的位置")]),t._v(" "),s("p",[t._v("3）语义分割")]),t._v(" "),s("p",[t._v("区分到图中每一点像素点，而不仅仅是矩形框框住")]),t._v(" "),s("p",[t._v("4）目标检测")]),t._v(" "),s("p",[t._v("简单来说就是回答图片里面有什么，分别在哪里，把它们用矩形框框起来")]),t._v(" "),s("p",[t._v("5）实例分割")]),t._v(" "),s("p",[t._v("目标检测和语义分割的结合，可精确到物体的边缘，需要标注出图上同一物体的不同个体")]),t._v(" "),s("h3",{attrs:{id:"图像定位"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图像定位"}},[t._v("#")]),t._v(" 图像定位")]),t._v(" "),s("p",[t._v("对于单纯的分类问题，比较容易理解，给定一副图片，我们输出一个标签类别，而定位有点复杂，需要输出四个数字（x, y, w, h），图像中某一个点的坐标（x, y），以及图像的宽度和高度，有了这四个数字，我们可以很容易地找到物体的边框")]),t._v(" "),s("h2",{attrs:{id:"章节13-unet图像语义分割"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节13-unet图像语义分割"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节13 Unet图像语义分割")])]),t._v(" "),s("p",[t._v("图像语义分割是图像处理和是计算机视觉技术中关于图像理解的重要一环，也是AI领域中一个重要的分支")]),t._v(" "),s("p",[t._v("语义分割对图像中每一个像素点进行分类，确定每个点的类别（如属于背景、边缘或身体等）")]),t._v(" "),s("p",[t._v("这里需要和实例分割区分开来。它没有分离同一类的实例；我们关心的只是每个像素的类别，如果输入对像中有两个相同类别的对象，则")]),t._v(" "),s("p",[t._v("分割本身不将他们区分为单独的对象")]),t._v(" "),s("img",{staticStyle:{zoom:"33%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240720134435049.png",alt:"image-20240720134435049"}}),t._v(" "),s("h3",{attrs:{id:"图像语义分割应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图像语义分割应用"}},[t._v("#")]),t._v(" 图像语义分割应用")]),t._v(" "),s("ol",[s("li",[t._v("自动驾驶汽车：\n我们需要为汽车增加必要的感知，以了解他们所处的环境，以便自动驾驶的汽车可以安全行驶；")]),t._v(" "),s("li",[t._v("医学图像诊断：机器可以增强放射医生进行的分析，大大减少了运行诊断测试所需的时间；")]),t._v(" "),s("li",[t._v("无人机着陆点判断等")])]),t._v(" "),s("h3",{attrs:{id:"语义分割的目标"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#语义分割的目标"}},[t._v("#")]),t._v(" 语义分割的目标")]),t._v(" "),s("ol",[s("li",[t._v("一般是将一张RGB图像（height*width*3）或是灰度图（height*width*1）作为输入")]),t._v(" "),s("li",[t._v("输出的是分割图，其中每一个像素包含了其类别的标签（height*width*1）")])]),t._v(" "),s("p",[t._v("目前在图像分割领域比较成功的算法，有很大一部分都来自于同一个先驱：Fully Convolutional Network（FCN），或者叫全卷积网络")]),t._v(" "),s("p",[t._v("FCN将分类转换成用于分割任务的网络结构，并证明了在分割问题上，可以实现端到端的网络训练。，成为了深度学习解决分割问题的奠基石")]),t._v(" "),s("p",[t._v("FCN用卷积层和池化层替代了分类网络中的全连接层，从而使得网络结构可以适应像素级的稠密估计任务")]),t._v(" "),s("h3",{attrs:{id:"语义分割的unet网络结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#语义分割的unet网络结构"}},[t._v("#")]),t._v(" 语义分割的UNET网络结构")]),t._v(" "),s("p",[t._v("是2015年诞生的模型，它几乎是当前segmentation项目中应用最广的模型，Unet能从更少的训练图像中进行学习")]),t._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240720135908597.png",alt:"image-20240720135908597"}}),t._v(" "),s("p",[t._v("Unet已经成为大多做医疗影响语义分割任务的最基础的网络结构。也启发了大量研究者去思考U型语义分割网络")]),t._v(" "),s("p",[t._v("U-net网络非常简单，前半部分作用是特征提取，后半部分是上采样。在一些文献中也把这样的结构叫做编码器-解码器结构")]),t._v(" "),s("h3",{attrs:{id:"输入和输出"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#输入和输出"}},[t._v("#")]),t._v(" 输入和输出")]),t._v(" "),s("p",[t._v("网络的输入可以为任意尺寸的彩色图像；输出与输入尺寸相同，通道数为：n（目标类别数）+1（背景）")]),t._v(" "),s("h3",{attrs:{id:"上采样-upsampling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#上采样-upsampling"}},[t._v("#")]),t._v(" 上采样（Upsampling）")]),t._v(" "),s("p",[t._v("由于在卷积过程中，我们的特征图像变得很小（比如长宽变为原图像的1/32），为了得到原图像大小的稠密像素预测，我们需要进行上采样。容易想到三种方式，分别对应最大池化、平均池化和卷积操作的反过来使用")]),t._v(" "),s("ol",[s("li",[t._v("插值法")]),t._v(" "),s("li",[t._v("反池化")]),t._v(" "),s("li",[t._v("反卷积（转置卷积）")])]),t._v(" "),s("h3",{attrs:{id:"iou评价指标"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#iou评价指标"}},[t._v("#")]),t._v(" IOU评价指标")]),t._v(" "),s("p",[t._v("IoU也可以叫做交并比，是一种测量在特定数据集中检测相应物体准确度的一个标准")]),t._v(" "),s("p",[t._v("IoU是一个简单的测量标准，只要是在输出中得出一个预测范围的任务，都可以用IoU来进行测量，比如目标检测、语义分割等等")]),t._v(" "),s("p",[t._v("IoU表示产生的候选框与原标记框的交叠率或者说重叠度，也就是它们的交集与并集的比值。最理想的情况是完全重叠，比值为1")]),t._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240720171911645.png",alt:"image-20240720171911645"}}),t._v(" "),s("h2",{attrs:{id:"章节14-linknet-图像语义分割"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节14-linknet-图像语义分割"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节14 LinkNet 图像语义分割")])]),t._v(" "),s("p",[t._v("像素级的图像语义分割不仅需要精确，还需要高效，以便应用到实时应用（real-time application）中。比如自动驾驶汽车等\n现有的方法精度可能比较高，但往往参数量巨大，运算开销很高。为了解决这个问题，论文提出了LinkNet")]),t._v(" "),s("h3",{attrs:{id:"网络结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#网络结构"}},[t._v("#")]),t._v(" 网络结构")]),t._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240803182120874.png",alt:"image-20240803182120874"}}),t._v(" "),s("p",[t._v("其中分为输入、输出、编码器和解码器部分")]),t._v(" "),s("p",[t._v("编码器、解码器构造：")]),t._v(" "),s("p",[s("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240803182242215.png",alt:"image-20240803182242215"}}),s("img",{staticStyle:{zoom:"45%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240803182303526.png",alt:"image-20240803182303526"}})]),t._v(" "),s("h3",{attrs:{id:"效果比较"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#效果比较"}},[t._v("#")]),t._v(" 效果比较")]),t._v(" "),s("p",[t._v("将LinkNet与常见网络结构在两个指标上进行比较：")]),t._v(" "),s("p",[t._v("速度：一次前向运算所需操作数、运行时间")]),t._v(" "),s("p",[t._v("精度：使用Cityscapes和CamVid数据集进行测试")]),t._v(" "),s("img",{staticStyle:{zoom:"33%"},attrs:{src:"https://whh-bucket.oss-cn-guangzhou.aliyuncs.com/image/image-20240803185120085.png",alt:"image-20240803185120085"}}),t._v(" "),s("h2",{attrs:{id:"章节16-简单文本分类与词嵌入表示"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#章节16-简单文本分类与词嵌入表示"}},[t._v("#")]),t._v(" "),s("strong",[t._v("章节16 简单文本分类与词嵌入表示")])]),t._v(" "),s("h3",{attrs:{id:"文本的理解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文本的理解"}},[t._v("#")]),t._v(" 文本的理解")]),t._v(" "),s("p",[t._v("文本是常用的序列化数据类型之一。文本数据可以看作是一个字符序列或词的序列。对大多数问题，我们都将文本看作词序列。")]),t._v(" "),s("p",[t._v("深度学习序列模型（如RNN及其变体）能够较好的对序列化数据建模。")]),t._v(" "),s("ol",[s("li",[t._v("自然语言理解")]),t._v(" "),s("li",[t._v("文献分类、情感分类；")]),t._v(" "),s("li",[t._v("问答系统等")])]),t._v(" "),s("p",[t._v("深度学习模型并不能理解文本，因此需要将文本转换为数值的表示形式。")]),t._v(" "),s("p",[t._v("将文本转换为数值表示形式的过程称为向量化过程，可以用不同的方式来完成")]),t._v(" "),s("h3",{attrs:{id:"文本向量化的方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文本向量化的方法"}},[t._v("#")]),t._v(" 文本向量化的方法")]),t._v(" "),s("ol",[s("li",[t._v("传统机器学习中：tf-idf算法")]),t._v(" "),s("li",[t._v("独热编码：one-hot 或者 k-hot")]),t._v(" "),s("li",[t._v("散列编码")]),t._v(" "),s("li",[t._v("文本词嵌入（word embedding）")])])])}),[],!1,null,null,null);s.default=i.exports}}]);